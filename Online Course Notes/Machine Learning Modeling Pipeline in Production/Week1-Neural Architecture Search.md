__Learning Objectives__

1. Recognize the cases where Neural Architecture Search is the appropriate tool to find the right model architecture.
2. Distinguish between trainable parameters and hyperparameters
3. Judge when manual parameter search does not scale well
4. Identify search spaces and summarize the best strategies to navigate this space to find optimal architectures.
5. Differentiate the advantages and disadvantages AutoML for different use cases
6. Carry out different metric calculations to assess AutoML efficacy
7. Identify some cloud AutoML offerings and recognize their strengths and weaknesses

## Neural Architecture Search
Neural architecture search, or NAS, it's a technique for automating the design of neural networks. 
- Models found by NAS are often on par with or outperform hand designed architectures for many types of problem.
- The goal of NAS is to find the optimal architecture.
- The Keras team has released one of the best, Keras Tuner, which is a library to easily perform hyperparameter tuning with TensorFlow 2.0.
  

